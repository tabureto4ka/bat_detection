{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vovaf\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\vovaf\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vovaf\\image\\yolov3.pt\n",
      "c:\\Users\\vovaf\\image\\project-1-at-2023-11-29-13-16-30c025dc.pt\n"
     ]
    }
   ],
   "source": [
    "detector = ObjectDetection()\n",
    "print(os.path.join(exec_path, \"yolov3.pt\"))\n",
    "path = os.path.join(exec_path, 'project-1-at-2023-11-29-13-16-30c025dc.pt')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid model file dataset.zip. Please parse in a '.pt' and '.pth' model file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vovaf\\image\\code.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vovaf/image/code.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m detector\u001b[39m.\u001b[39msetModelTypeAsYOLOv3()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vovaf/image/code.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m detector\u001b[39m.\u001b[39;49msetModelPath(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(exec_path, \u001b[39m\"\u001b[39;49m\u001b[39mdataset.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vovaf/image/code.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m detector\u001b[39m.\u001b[39mloadModel()\n",
      "File \u001b[1;32mc:\\Users\\vovaf\\anaconda3\\Lib\\site-packages\\imageai\\Detection\\__init__.py:206\u001b[0m, in \u001b[0;36mObjectDetection.setModelPath\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39m'setModelPath()' function is required and is used to set the file path to the model adopted from the list of the\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39mavailable 3 model types. The model path must correspond to the model type.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39m:param model_path:\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(path):\n\u001b[1;32m--> 206\u001b[0m     extension_check(path)\n\u001b[0;32m    207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__model_path \u001b[39m=\u001b[39m path\n\u001b[0;32m    208\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__model_loaded \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vovaf\\anaconda3\\Lib\\site-packages\\imageai\\backend_check\\model_extension.py:7\u001b[0m, in \u001b[0;36mextension_check\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou are trying to use a Tensorflow model with ImageAI. ImageAI now uses PyTorch as backed as from version 3.0.2 . If you want to use the Tensorflow models or a customly trained \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m\u001b[39m model, install ImageAI 2.1.6 or earlier. To use the latest Pytorch models, see the documentation in https://imageai.readthedocs.io/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39melif\u001b[39;00m file_path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m file_path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid model file \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(file_path)\u001b[39m}\u001b[39;00m\u001b[39m. Please parse in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m\u001b[39m model file.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid model file dataset.zip. Please parse in a '.pt' and '.pth' model file."
     ]
    }
   ],
   "source": [
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(exec_path, \"dataset.zip\"))\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vovaf\\image\\code.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vovaf/image/code.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mdetectObjectsFromImage(input_image\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(exec_path, \u001b[39m\"\u001b[39;49m\u001b[39m5f91e4d6f110558f27fda432.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vovaf/image/code.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                        output_image_path\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(exec_path, \u001b[39m\"\u001b[39;49m\u001b[39mnew_obj.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\vovaf\\anaconda3\\Lib\\site-packages\\imageai\\Detection\\__init__.py:322\u001b[0m, in \u001b[0;36mObjectDetection.detectObjectsFromImage\u001b[1;34m(self, input_image, output_image_path, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, display_box, custom_objects)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetectObjectsFromImage\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    295\u001b[0m             input_image: Union[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray, Image\u001b[39m.\u001b[39mImage],\n\u001b[0;32m    296\u001b[0m             output_image_path: \u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m             custom_objects: List\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    302\u001b[0m            ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[List[List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mfloat\u001b[39m, Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]]], np\u001b[39m.\u001b[39mndarray, List[np\u001b[39m.\u001b[39mndarray], List[\u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    303\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m    Detects objects in an image using the unique classes provided\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m    by COCO.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m    confidence.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__model\u001b[39m.\u001b[39;49meval()\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__model_loaded:\n\u001b[0;32m    324\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__model_path:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "list = detector.detectObjectsFromImage(input_image=os.path.join(exec_path, \"5f91e4d6f110558f27fda432.jpg\"),\n",
    "                                       output_image_path=os.path.join(exec_path, \"new_obj.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = detector.detectObjectsFromImage(input_image=os.path.join(exec_path, \"9qeyhmmEiq98jjHRQNaKVY.jpeg\"),\n",
    "                                       output_image_path=os.path.join(exec_path, \"new_9qeyhmmEiq98jjHRQNaKVY.jpeg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
